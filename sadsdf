import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime

URL = "https://en.wikipedia.org/wiki/2025%E2%80%9326_Premier_League"

print("Downloading fixtures from Wikipedia...")

headers = {"User-Agent": "Mozilla/5.0"}
r = requests.get(URL, headers=headers)
soup = BeautifulSoup(r.text, "lxml")

matches = []

tables = soup.find_all("table", class_="wikitable")

for table in tables:
    rows = table.find_all("tr")
    for row in rows:
        cols = [c.get_text(strip=True) for c in row.find_all("td")]
        if len(cols) < 5:
            continue

        date_text = cols[0]
        home = cols[1]
        score = cols[2]
        away = cols[3]

        try:
            dt = datetime.strptime(date_text, "%d %B %Y")
            formatted_date = dt.strftime("%Y-%m-%d")
        except:
            continue

        matches.append({
            "date": formatted_date,
            "time": "",
            "home": home,
            "away": away,
            "score": score if "-" in score else ""
        })

print(f"Scraped {len(matches)} matches")

# Group into matchdays (10 matches each)
matchdays = []
for i in range(0, len(matches), 10):
    matchdays.append({
        "matchday": (i // 10) + 1,
        "matches": matches[i:i+10]
    })

schedule = {
    "competition": "Premier League",
    "season": "2025/2026",
    "matchdays": matchdays
}

with open("schedule.json", "w") as f:
    json.dump(schedule, f, indent=2)

print("âœ… schedule.json created")
